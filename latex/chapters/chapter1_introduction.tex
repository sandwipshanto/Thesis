\chapter{Introduction}
\label{ch:introduction}

\section{Overview}
\label{sec:overview}

Large Language Models (LLMs) have transformed human-computer interaction, serving billions of users worldwide through applications ranging from customer service chatbots to educational tools and creative assistants. The release of models like ChatGPT \citep{openai2023}, Llama \citep{dubey2024}, Gemini \citep{google2024}, and Mistral has democratized access to powerful AI systems, enabling users from diverse linguistic backgrounds to interact with these technologies in their native languages or preferred communication styles. However, this global accessibility introduces critical safety challenges that remain poorly understood for low-resource languages, particularly in the context of adversarial attacks exploiting code-mixing and phonetic perturbations.

\section{Motivation and Research Problem}
\label{sec:motivation}

While extensive research has focused on English-language safety mechanisms \citep{ganguli2022, zou2023}, and recent work has begun exploring multilingual vulnerabilities \citep{deng2023, yong2023}, low-resource Indic languages remain severely understudied in the context of adversarial robustness. This gap is particularly concerning for Bangla, the world's eighth most spoken language with 230 million native speakers. Bangla speakers frequently use romanized Banglish in digital communication, yet current LLM safety training predominantly focuses on English and major European languages. Code-mixing---the practice of alternating between multiple languages within a single conversation---is the default communication mode for millions of South Asian internet users, creating a potential vulnerability surface that has received minimal academic attention.

Recent work by \citet{aswal2025} demonstrated that Hindi-English (Hinglish) code-mixing combined with phonetic perturbations can bypass LLM safety filters with high success rates through a tokenization disruption mechanism. Their findings revealed that romanized Hindi text fragments into smaller subword tokens compared to English equivalents, preventing safety classifiers from recognizing harmful intent. This raises a critical question: are other Indic languages with similar romanization patterns similarly vulnerable, and do their unique linguistic properties create distinct attack patterns?

Bangla presents a particularly compelling case study for several reasons. First, unlike Hindi's relatively standardized Devanagari romanization schemes, Bangla romanization (Banglish) has multiple valid variants for the same word, creating additional complexity for tokenization. Second, Bangla's distinct phonetic properties---including nasalization, consonant clusters, and vowel harmony---create unique tokenization patterns that may interact differently with safety mechanisms. Third, Bangla likely comprises a smaller proportion of LLM training corpora compared to Hindi, potentially resulting in weaker safety coverage. Finally, with 230 million speakers globally, this population deserves comprehensive safety protections that account for their actual language use patterns.

The research gap is substantial. While English jailbreaking has been extensively studied \citep{wei2023, zou2023} and Hinglish code-mixing attacks have been recently demonstrated \citep{aswal2025}, no prior work has investigated Bangla-English code-mixing attacks, evaluated Bangla safety coverage in major LLMs, or analyzed Bangla-specific linguistic vulnerabilities that might enable adversarial exploitation.

The research gap is substantial. While English jailbreaking has been extensively studied \citep{wei2023, zou2023} and Hinglish code-mixing attacks have been recently demonstrated \citep{aswal2025}, no prior work has investigated Bangla-English code-mixing attacks, evaluated Bangla safety coverage in major LLMs, or analyzed Bangla-specific linguistic vulnerabilities that might enable adversarial exploitation.

\section{Research Objectives}
\label{sec:objectives}

This research aims to achieve the following four objectives:

\begin{enumerate}
    \item \textbf{Develop and Validate Bangla-English Code-Mixed Attack Methodology:} Establish a systematic three-step prompt transformation pipeline that adapts the Hindi-English code-mixing approach \citep{aswal2025} to Bangla's unique linguistic features, including non-standard romanization patterns and distinct phonetic properties. This objective involves creating 50 base prompts across 10 harmful categories and systematically transforming them through code-mixing (CM) and phonetic perturbation (CMP) stages.
    
    \item \textbf{Characterize Bangla-Specific Attack Patterns:} Identify and analyze the phonetic perturbations and romanization conventions that maximize jailbreak effectiveness in Bangla-English code-mixed prompts. This includes determining whether perturbing English words versus Bangla words yields differential attack success rates, and documenting which specific romanization variations most effectively fragment tokens to bypass safety filters.
    
    \item \textbf{Evaluate Cross-Model Vulnerability Consistency:} Assess the vulnerability of major LLMs (GPT-4o-mini, Llama-3-8B, Mistral-7B) to Bangla-English code-mixed attacks across varying experimental conditions including five jailbreak templates (None, OM, AntiLM, AIM, Sandbox) and three temperature settings (0.2, 0.6, 1.0). This objective seeks to determine whether Bangla-based attacks represent a universal vulnerability across model architectures or exhibit model-specific patterns.
    
    \item \textbf{Validate Tokenization Disruption as Attack Mechanism:} Empirically verify whether the tokenization fragmentation mechanism proposed and validated for Hindi-English attacks \citep{aswal2025} explains Bangla jailbreak success. This involves analyzing correlations between token fragmentation rates and attack success rates (AASR) across the English, CM, and CMP prompt sets to determine if similar patterns emerge for Bangla.
\end{enumerate}

\section{Research Questions}
\label{sec:research-questions}

Building on these objectives, this thesis addresses four primary research questions:

\subsection{RQ1: Code-Mixing Effectiveness}
\textit{Does Bangla-English code-mixing with phonetic perturbations bypass LLM safety filters?}

We hypothesize that the English$\rightarrow$CM$\rightarrow$CMP progression will successfully increase attack success rates for Bangla, similar to patterns observed for other code-mixed languages.

\subsection{RQ2: Bangla-Specific Patterns}
\textit{Which phonetic and romanization features enable Bangla attacks?}

We investigate whether Bangla's unique linguistic properties (non-standard romanization, specific phonology) create distinct attack patterns compared to general code-mixing strategies.

\subsection{RQ3: Model Vulnerability}
\textit{Are all major LLMs vulnerable to Bangla attacks?}

We test whether model vulnerability is consistent across different architectures and whether safety training generalizes to Bangla-English code-mixing.

\subsection{RQ4: Tokenization Mechanism}
\textit{Does tokenization disruption explain Bangla attack success?}

We examine whether the tokenization fragmentation hypothesis validated for other languages applies to Bangla and quantify the correlation between token fragmentation and attack success.

\section{Contributions}
\label{sec:contributions}

This thesis makes six primary contributions to multilingual LLM security research:

\begin{enumerate}
    \item \textbf{First Bangla code-mixing jailbreaking study:} Systematic evaluation of 230M speaker population previously untested in adversarial contexts (200 prompts across 10 categories, 3 major LLMs, 27,000 responses)
    
    \item \textbf{Bangla-specific attack optimization:} Discovery that perturbing \textbf{English words} within Banglish prompts is 85\% more effective than perturbing Bangla words
    
    \item \textbf{Template ineffectiveness finding:} Contrary to expectations, jailbreak templates \textbf{reduce} effectiveness for Bangla (46.2\% AASR with ``None'' template vs. 35.1-42.5\% with jailbreak templates)
    
    \item \textbf{Tokenization mechanism application:} Application of tokenization disruption hypothesis (empirically validated for Hindi-English via Integrated Gradients by Aswal \& Jaiswal, 2025) to Bangla-English context, with AASR patterns consistent with fragmentation-based explanation
    
    \item \textbf{Romanization variability analysis:} Identification of Bangla's non-standard romanization as a unique vulnerability creating multiple valid tokenization paths
    
    \item \textbf{Scalable framework:} Replicable methodology applicable to 20+ other Indic languages at $\sim$\$1.50-2.00 per language
\end{enumerate}

\section{Thesis Organization}
\label{sec:organization}

The remainder of this thesis is organized as follows. Chapter~\ref{ch:background} reviews related work on LLM jailbreaking, multilingual safety, code-mixing, and phonetic perturbations, establishing the theoretical foundation for our investigation. Chapter~\ref{ch:methodology} describes our systematic three-step methodology for generating Bangla code-mixed prompts with phonetic perturbations, including the prompt transformation pipeline and jailbreak template implementations. Chapter~\ref{ch:experimental} details the comprehensive experimental setup including model selection, dataset statistics, evaluation metrics, and statistical validation methods. Chapter~\ref{ch:results} presents empirical findings for all four research questions, supported by quantitative analysis and statistical significance testing. Chapter~\ref{ch:discussion} discusses the broader implications of our findings, compares results with related work on multilingual vulnerabilities, and addresses methodological considerations. Chapter~\ref{ch:limitations} acknowledges important limitations including dataset size constraints, model scope restrictions, and experimental boundary conditions. Chapter~\ref{ch:ethical} addresses critical ethical considerations including responsible disclosure protocols and dataset handling procedures. Finally, Chapter~\ref{ch:conclusion} concludes with key takeaways and promising directions for future research in multilingual LLM security.
