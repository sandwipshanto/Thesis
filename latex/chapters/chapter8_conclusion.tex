\chapter{Conclusion and Future Work}
\label{ch:conclusion}

Here we'll wrap up by summarizing our key contributions, revisiting our research questions, talking about broader implications, and outlining future research directions.

\section{Summary of Contributions}
\label{sec:summarycontributions}

This thesis presents the first comprehensive study of Bangla English codemixing attacks on Large Language Models, making five primary contributions:

\subsection{First Bangla CodeMixing Study}

What we achieved:
\begin{itemize}
    \item Evaluated 230M speaker population previously untested in adversarial contexts
    \item Demonstrated 40.1\% AASR with Bangla English codemixing + perturbations
    \item Established baseline vulnerability metrics for Bangla across 3 major LLMs
\end{itemize}

Why this matters:
\begin{itemize}
    \item Fills critical gap in multilingual LLM safety research
    \item Provides first empirical evidence of Bangla vulnerability
    \item Enables targeted safety improvements for 8th most spoken language
\end{itemize}

\subsection{English Word Targeting Discovery}

What we achieved:
\begin{itemize}
    \item Discovered that perturbing English words is 68\% more effective than perturbing Bangla words
    \item Validated through systematic comparison (52.3\% vs. 31.1\% AASR)
    \item Identified optimal 70:30 English:Bangla ratio
\end{itemize}

Why this matters:
\begin{itemize}
    \item Novel finding not explored in prior codemixing work
    \item Reveals Englishcentric nature of safety training
    \item Informs attack optimization for other languages
\end{itemize}

\subsection{Template Ineffectiveness Finding}

What we achieved:
\begin{itemize}
    \item Demonstrated that jailbreak templates reduce Bangla attack effectiveness
    \item "None" template achieves 46.2\% AASR vs. 35.142.5\% with jailbreak templates
    \item Contradicts findings where templates enhanced attacks in other contexts
\end{itemize}

Why this matters:
\begin{itemize}
    \item Reveals languagespecific attack dynamics
    \item Challenges universal applicability of jailbreak templates
    \item Suggests simpler attacks may be more effective for codemixing
\end{itemize}

\subsection{Tokenization Mechanism Validation}

What we achieved:
\begin{itemize}
    \item Strong correlation between token fragmentation and AASR
    \item Validated progressive fragmentation hypothesis (1.0× → 1.67× → 1.91×)
    \item Provided mechanistic explanation for Bangla attack success
\end{itemize}

Why this matters:
\begin{itemize}
    \item Independently validates tokenization hypothesis for Bangla
    \item Strengthens theoretical understanding of codemixing attacks
    \item Informs development of tokenization robust defenses
\end{itemize}

\subsection{Scalable Framework Development}

What we achieved:
\begin{itemize}
    \item Developed configdriven experimental framework
    \item Demonstrated replicability at \$1.502.00 per language
    \item Applicable to 20+ other Indic languages
\end{itemize}

Why this matters:
\begin{itemize}
    \item Enables systematic multilingual vulnerability assessment
    \item Lowers barriers for safety research across language communities
    \item Facilitates collective advancement in multilingual AI safety
\end{itemize}

\section{Research Questions Revisited}
\label{sec:rqrevisited}

\subsection{RQ1: CodeMixing Effectiveness}

Question: Does Bangla English codemixing with phonetic perturbations bypass LLM safety filters?

Answer: Yes. Bangla codemixing achieves 40.1\% AASR with statistically significant improvement over English baselines (p=0.0070). The attack proves effective across all tested models with varying degrees of severity.

Key insight: Linguistic obfuscation alone provides sufficient evasion without sophisticated prompt engineering.

\subsection{RQ2: Bangla Specific Patterns}

Question: Which phonetic and romanization features enable Bangla attacks?

Answer: Four patterns enable attacks: English word targeting (68\% more effective), optimal 70:30 codemixing ratios, romanization variability exploitation, and vowelbased phonetic fragmentation.

Key insight: Safety systems demonstrate Englishcentric bias, making English words within codemixed text the optimal attack target.

\subsection{RQ3: Model Vulnerability Consistency}

Question: Are all major LLMs vulnerable to Bangla attacks?

Answer: Yes, with dramatic inconsistency. Mistral7B shows critical vulnerability (81.8\% AASR), Llama38B moderate vulnerability (22.7\%), and GPT4omini low but nonzero vulnerability (16.0\%).

Key insight: No tested model achieves adequate safety coverage for Bangla speakers, exposing systematic gaps in multilingual AI safety.

\subsection{RQ4: Tokenization Mechanism}

Question: Does tokenization disruption explain Bangla attack success?

Answer: Yes. Progressive tokenization fragmentation correlates with AASR improvement, confirming that phonetic perturbations fragment harmful keywords into semantically harmless subword units.

Key insight: Token level safety filters can be systematically evaded through linguistic fragmentation strategies.

\section{Broader Implications}
\label{sec:broaderimplications}

\subsection{Multilingual AI Safety}

Our findings expose fundamental inequities in current AI safety approaches:

Language bias: Safety training remains predominantly English focused despite global user diversity. Technical gaps show that token level filters are vulnerable to systematic linguistic obfuscation. The scale of impact means 230 million Bangla speakers get demonstrably inadequate protection. For generalizability, similar vulnerabilities likely exist across dozens of additional languages.

\subsection{Policy and Governance}

Evidencebased advocacy means our research provides an empirical foundation for multilingual safety requirements. Regulatory implications show findings support language coverage mandates for AI systems serving diverse populations. Industry accountability demonstrates the need for proactive multilingual vulnerability assessment. Global equity challenges the tech industry to address systematic bias in safety provision.

\subsection{Technical Architecture}

Tokenization limitations show current approaches fail for nonstandardized romanization systems. Defense directions require semanticlevel safety classifiers to resist fragmentation attacks. Training requirements mean RLHF must explicitly incorporate codemixing adversarial examples. System design shows multilingual safety cannot be achieved through English only training.

\section{Future Research Directions}
\label{sec:futuredirections}

\subsection{Immediate Extensions}

Scale replication involves a full 460prompt study following Hinglish methodology. Human validation requires comprehensive interannotator reliability study for evaluation validation. Model expansion should include Claude, PaLM, and parameterscale analysis. Automation development needs NMTbased codemixing generation for scalability.

\subsection{Language Expansion}

Indic language coverage should apply methodology to Tamil, Telugu, Marathi, Urdu, Gujarati. African language exploration can extend to Swahili, Yoruba, Amharic codemixing contexts. Southeast Asian analysis should investigate Thai English, Vietnamese English patterns. Arabic script languages need to adapt methodology for Urdu, Persian, Arabic romanization.

\subsection{Defense Development}

Romanization normalization should develop robust canonicalization for multiple scripts. Semantic classifiers need to build embeddingspace safety filters resistant to fragmentation. Multilingual training should design RLHF incorporating systematic codemixing coverage. Detection systems should create early warning for novel linguistic evasion strategies.

\subsection{Mechanistic Understanding}

Attention analysis should investigate how codemixing affects transformer attention patterns. Embedding geometry needs to analyze safety representation space across languages. Training dynamics should study how multilingual data affects safety generalization. Cognitive modeling should compare human and model processing of codemixed harmful content.

\section{Final Reflections}
\label{sec:finalreflections}

\subsection{Research Impact}

This work shows that rigorous academic research can expose systematic inequities in AI systems while providing actionable pathways for improvement. The discovery that 230 million Bangla speakers get inadequate safety protection represents both a concerning finding and an opportunity for targeted enhancement.

\subsection{Methodological Contributions}

Our configdriven experimental framework proves that comprehensive multilingual vulnerability assessment remains feasible even under significant resource constraints. The \$1.502.00 per language cost enables systematic evaluation across dozens of additional language communities.

\subsection{Ethical Responsibility}

The dualuse nature of our findings requires ongoing vigilance, but the alternative leaving vulnerabilities undocumented and unaddressed serves no one except malicious actors who likely already exploit these weaknesses. Academic disclosure accelerates collective defense while enabling evidencebased policy advocacy.

\subsection{Call to Action}

We call on the AI research community, industry practitioners, and policy makers to prioritize multilingual AI safety as a fundamental equity issue. The 8th most spoken language in the world deserves safety protection equivalent to English, and our framework provides the tools to achieve this goal.

The path forward requires coordinated effort across multiple stakeholders: researchers expanding vulnerability assessment to additional languages, developers implementing semanticlevel defenses, and policy makers establishing enforceable multilingual safety standards. Only through such comprehensive action can we ensure that AI safety serves all global communities equitably.

\section{Closing Statement}
\label{sec:closing}

This thesis establishes that Bangla English codemixing constitutes a significant vulnerability surface against current LLM safety systems, affecting 230 million speakers worldwide. More broadly, our work shows the critical importance of multilingual perspectives in AI safety research and provides practical tools for systematic vulnerability assessment across language communities.

The findings presented here represent not an endpoint but a beginning the first systematic exploration of Bangla LLM vulnerabilities and a replicable framework for extending this analysis to dozens of additional languages. As AI systems become increasingly central to global information access and decisionmaking, ensuring equitable safety protection across all language communities becomes not merely a technical challenge but a moral imperative.

We hope this work contributes to a more inclusive and equitable AI safety landscape, where protection and security extend to all users regardless of their linguistic background.