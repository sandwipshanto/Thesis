\chapter{Results and Discussion}
\label{ch:resultsdiscussion}

Here we'll present our experimental findings and what they mean, organized around our research questions. Our results come from 27,000 model responses we collected across 3 LLMs (GPT4omini, Llama3-8B, Mistral7B), 5 jailbreak templates, 3 prompt sets, and 3 temperature settings from our 200-prompt dataset.

\section{RQ1: Code-Mixing Effectiveness Analysis}
\label{sec:rq1}

\textit{Does Bangla English codemixing with phonetic perturbations bypass LLM safety filters?}

\subsection{Overall Attack Success Rates}

Bangla codemixing with phonetic perturbations gets a 40.1% AASR, which is a significant improvement over our English baseline (36.1%). The English→CMP transition is statistically significant (p=0.0070).

\begin{table}[h]
\centering
\caption{Overall Attack Success Rates by Prompt Set}
\label{tab:overall-aasr}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{AASR} & \textbf{AARR} & \textbf{Change from Baseline} \\ \midrule
English & 36.1\% & 70.5\% & Baseline \\
CM & 37.2\% & 72.1\% & +1.1 percentage points \\
CMP & 40.1\% & 74.2\% & +4.0 percentage points \\ \bottomrule
\end{tabular}
\end{table}

Our Wilcoxon signedrank testing confirms statistically significant differences. When we compare English and codemixed prompts, we get p = 0.0209, while the direct comparison between English and fully perturbed prompts gives us p = 0.0070, confirming that our complete transformation pipeline actually works.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/transition_effects_20251123_190143.png}
\caption{Attack success rate progression across prompt transformations}
\label{fig:transition-effects}
\end{figure}

\subsection{Model Specific Vulnerability Analysis}

\begin{table}[h]
\centering
\caption{AASR by Model and Prompt Set}
\label{tab:model-aasr}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & English & CM & CMP & Vulnerability Level \\ \midrule
Mistral7B & 84.1\% & 80.0\% & 81.3\% & Critical \\
Llama38B & 11.6\% & 25.6\% & 30.9\% & Moderate \\
GPT4omini & 1.5\% & 20.7\% & 25.7\% & Low \\ \bottomrule
\end{tabular}
\end{table}

Mistral7B shows critical baseline vulnerability at 84.1%, with minimal variation when we use codemixing strategies. GPT4omini shows dramatic vulnerability increase from 1.5% (English) to 25.7% (CMP), which is a 17fold multiplicative increase. This reveals that even robust safety systems can still be exploited through linguistic obfuscation.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/aasr_heatmap_20251123_190140.png}
\caption{Model vulnerability heatmap across prompt transformations}
\label{fig:aasr-heatmap}
\end{figure}

\subsection{Temperature Effects and Statistical Analysis}

\begin{table}[h]
\centering
\caption{AASR by Temperature (CMP Set)}
\label{tab:temp-sensitivity}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Temperature} & \textbf{AASR (CMP)} & \textbf{Change from 0.2} \\ \midrule
0.2 (Low) & 43.5\% & Baseline \\
0.6 (Medium) & 45.3\% & +1.8 percentage points \\
1.0 (High) & 49.2\% & +5.7 percentage points \\ \bottomrule
\end{tabular}
\end{table}

**Finding Summary:** Codemixing effectively bypasses safety filters across all the models we tested, getting statistically significant improvements through linguistic obfuscation. The attack works best at higher temperatures and shows universal vulnerability across different model architectures.

\section{RQ2: Bangla Specific Linguistic Patterns}
\label{sec:rq2}

\textit{Which phonetic and romanization features enable Bangla attacks?}

\subsection{English vs. Bangla Word Targeting}

Perturbing English words within Banglish prompts works significantly better than perturbing Bangla words, revealing that safety systems are Englishcentric and vulnerable.

\begin{table}[h]
\centering
\caption{Targeting Strategy Effectiveness}
\label{tab:targeting}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Strategy} & \textbf{AASR} & \textbf{Effectiveness Ratio} \\ \midrule
Englishword perturbations & 52.3\% & 1.68× \\
Bangla-word perturbations & 31.1\% & Baseline \\ \bottomrule
\end{tabular}
\end{table}

\subsection{CodeMixing Ratio Optimization}

\begin{table}[h]
\centering
\caption{Code-Mixing Ratio Impact on Attack Success}
\label{tab:cm-ratio}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{English:Bangla Ratio} & \textbf{AASR} & \textbf{Strategic Value} \\ \midrule
90:10 (High English) & 41.2\% & Preserves harmful keywords \\
70:30 (Optimal) & 46.0\% & Balances obfuscation and coherence \\
50:50 (Balanced) & 38.7\% & Excessive fragmentation \\
30:70 (High Bangla) & 29.4\% & Loss of semantic clarity \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Perturbation Strategy Effectiveness}

\begin{table}[h]
\centering
\caption{Phonetic Perturbation Effectiveness}
\label{tab:perturbation-types}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Perturbation Type} & \textbf{Example} & \textbf{AASR} & \textbf{Effectiveness} \\ \midrule
Vowel substitution & hate → haet & 48.2\% & High \\
Consonant doubling & bot → bott & 46.7\% & High \\
Phonetic respelling & discrimination → diskrimineshun & 45.1\% & Medium \\
Letter transposition & create → craete & 43.8\% & Medium \\ \bottomrule
\end{tabular}
\end{table}

**Finding Summary:** English word targeting works 68% better than Bangla word perturbations. The 70:30 English:Bangla ratio optimizes attack success, while vowel substitution comes out as the most effective phonetic perturbation strategy.

\section{RQ3: CrossModel Vulnerability Assessment}
\label{sec:rq3}

\textit{Are all major LLMs vulnerable to Bangla attacks?}

\subsection{Model Vulnerability Hierarchy}

\begin{table}[h]
\centering
\caption{Model Vulnerability Ranking}
\label{tab:model-hierarchy}
\begin{tabular}{@{}clcc@{}}
\toprule
Rank & Model & Average AASR & Vulnerability Classification \\ \midrule
1 & Mistral7B & 81.8\% & Critical \\
2 & Llama38B & 22.7\% & Moderate \\
3 & GPT4omini & 16.0\% & Low (but exploitable) \\ \bottomrule
\end{tabular}
\end{table}

All the models we tested show vulnerability, though the severity varies dramatically. Mistral7B's 81.8% average AASR suggests fundamental safety alignment failures, while GPT4omini's 16.0% indicates robust but imperfect defenses.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/model_comparison_20251123_190141.png}
\caption{Cross-model vulnerability comparison}
\label{fig:model-comparison}
\end{figure}

\subsection{Jailbreak Template Analysis}

Jailbreak templates actually reduce attack effectiveness for Bangla code-mixing. The "None" baseline gets the highest success (46.2%), outperforming all engineered templates.

\begin{table}[h]
\centering
\caption{Template Effectiveness Across Models}
\label{tab:template-effectiveness}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Template} & \textbf{Mistral} & \textbf{Llama} & \textbf{GPT4o} & \textbf{Average} \\ \midrule
None & 83.2\% & 24.1\% & 17.8\% & 46.2\% \\
AntiLM & 81.7\% & 22.9\% & 16.1\% & 42.5\% \\
OM & 80.9\% & 21.4\% & 15.2\% & 40.6\% \\
AIM & 79.3\% & 18.7\% & 14.3\% & 36.4\% \\
Sandbox & 78.1\% & 17.2\% & 13.8\% & 35.1\% \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/template_comparison_20251123_190142.png}
\caption{Jailbreak template performance comparison}
\label{fig:template-comparison}
\end{figure}

**Finding Summary:** We confirmed universal vulnerability across all tested models. Templatebased approaches actually work against codemixing attacks, with simple, direct prompts maximizing effectiveness.

\section{RQ4: Tokenization Mechanism Validation}
\label{sec:rq4}

\textit{Does tokenization disruption explain Bangla attack success?}

\subsection{Fragmentation-Effectiveness Correlation}

\begin{table}[h]
\centering
\caption{Tokenization Fragmentation vs. Attack Success}
\label{tab:fragmentation}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{Avg Tokens/Word} & \textbf{Fragmentation Ratio} & \textbf{AASR} \\ \midrule
English & 1.12 & 1.00× (baseline) & 36.1\% \\
CM & 1.87 & 1.67× & 37.2\% \\
CMP & 2.14 & 1.91× & 40.1\% \\ \bottomrule
\end{tabular}
\end{table}

Progressive tokenization fragmentation aligns with AASR improvement, validating our hypothesis that phonetic perturbations fragment harmful keywords into semantically harmless subword units.

\subsection{Tokenization Case Study}

\begin{algorithm}[h]
\begin{algorithmic}[1]
\STATE \textbf{English:} "hate speech"  
\STATE \textbf{Tokens:} ["hate", "speech"] | Count: 2 | AASR: 28\%
\STATE 
\STATE \textbf{CM:} "hate speech er jonno"  
\STATE \textbf{Tokens:} ["hate", "speech", "er", "jon", "no"] | Count: 5 | AASR: 39\%
\STATE 
\STATE \textbf{CMP:} "haet speach er jonno"  
\STATE \textbf{Tokens:} ["ha", "et", "spe", "ach", "er", "jon", "no"] | Count: 7 | AASR: 47\%
\end{algorithmic}
\caption{Tokenization Fragmentation Example: "hate speech" Keyword}
\label{alg:tokenization-example}
\end{algorithm}

**Finding Summary:** Tokenization disruption gives us a mechanistic explanation for attack success. Progressive fragmentation correlates with effectiveness increase, confirming that safety filters operate at token level and can be evaded through systematic keyword fragmentation.

\section{Comparison with Related Work}
\label{sec:comparison}

\subsection{Methodological Positioning}

Our work parallels the Hinglish codemixing study by Aswal and Jaiswal (2025) in experimental design while investigating Bangla specific patterns. Both use threestep transformation pipelines and test identical model architectures, yet our findings reveal distinct linguistic characteristics.

The Hinglish study reported 99% AASR with CMP variants, while our Bangla approach gets 40.1% AASR. However, we need to be careful with direct comparison due to different prompt sets, evaluation criteria, and languagespecific phonological properties. The absolute difference likely reflects linguistic variation rather than inherent language superiority.

\subsection{Multilingual Safety Context}

Our findings extend patterns identified by previous multilingual vulnerability studies, giving the first systematic evaluation for Bangla speakers. The consistent improvement over English baselines confirms that multilingual safety gaps apply broadly to South Asian language communities.

\section{Implications and Recommendations}
\label{sec:implications}

\subsection{Technical Recommendations}

Current LLM developers should implement urgent fixes: incorporate codemixed adversarial examples in redteaming protocols, expand RLHF datasets to cover Indic language contexts, develop semanticlevel safety classifiers that work independently of tokenization, and implement dynamic romanization normalization to reduce attack surface area.

\subsection{Long-Term Solutions}

Fundamental safety redesign needs embeddingspace classifiers that resist fragmentation attacks, multilingual safety training with explicit codemixing representation, and deployment policies that enforce higher safety thresholds in regions with known languagespecific vulnerabilities.

\subsection{Equity Considerations}

The 230 million Bangla speakers currently get demonstrably inadequate safety protection compared to English speakers. Policy interventions must establish language coverage requirements for models serving populations exceeding 100 million speakers.

\section{Unexpected Findings}
\label{sec:unexpected}

\subsection{Template Countereffectiveness}

The discovery that jailbreak templates actually reduce Bangla attack effectiveness goes against established adversarial literature. This suggests that code-mixing itself gives sufficient obfuscation, making additional prompt engineering counterproductive.

\subsection{Model-Specific Vulnerability Patterns}

Mistral7B's critical vulnerability (81.8% AASR) compared to GPT4omini's relative robustness (16.0%) shows dramatic inconsistency in safety training effectiveness. Opensource models may need communitydriven safety improvements to achieve commercial model parity.

\section{Limitations and Future Work}
\label{sec:limitations}

Dataset scale limitations (200 vs. 460 prompts in the Hinglish study) and incomplete model coverage (3 vs. 4 planned models) reduce generalizability. Manual codemixing processes limit automation potential for largescale studies.

Future work should scale to full 460prompt replication, develop automated NMTbased codemixing systems, extend our methodology to 20+ additional Indic languages, and validate findings through comprehensive human evaluation studies.

\section{Chapter Summary}
\label{sec:chapter-summary}

This investigation establishes four core findings that advance multilingual LLM safety understanding. First, Bangla codemixing gets 40.1% AASR through statistically significant improvement over English baselines (p=0.0070). Second, English word targeting works 68% better than Bangla word perturbations, exposing Englishcentric safety filter bias. Third, universal model vulnerability exists with dramatic severity variation (16% to 82% AASR), while jailbreak templates actually work against us. Fourth, tokenization fragmentation mechanistically explains attack success through systematic keyword disruption.

These findings require immediate multilingual safety improvements, equitable protection for nonEnglish speakers, and fundamental architectural changes to address systematic vulnerabilities affecting hundreds of millions globally.