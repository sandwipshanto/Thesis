\chapter{Results and Discussion}
\label{ch:results-discussion}

This chapter presents our experimental findings and their interpretation, organized by research question. Results are based on 27,000 model responses collected across 3 LLMs (GPT-4o-mini, Llama-3-8B, Mistral-7B), 5 jailbreak templates, 3 prompt sets, and 3 temperature settings from a 200-prompt dataset.

\section{RQ1: Code-Mixing Effectiveness Analysis}
\label{sec:rq1}

\textit{Does Bangla-English code-mixing with phonetic perturbations bypass LLM safety filters?}

\subsection{Overall Attack Success Rates}

Bangla code-mixing with phonetic perturbations achieves 40.1\% AASR, representing a significant improvement over the English baseline (36.1\%). The English→CMP transition shows statistical significance (p=0.0070).

\begin{table}[h]
\centering
\caption{Overall Attack Success Rates by Prompt Set}
\label{tab:overall-aasr}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{AASR} & \textbf{AARR} & \textbf{Change from Baseline} \\ \midrule
English & 36.1\% & 70.5\% & Baseline \\
CM & 37.2\% & 72.1\% & +1.1 percentage points \\
CMP & 40.1\% & 74.2\% & +4.0 percentage points \\ \bottomrule
\end{tabular}
\end{table}

Wilcoxon signed-rank testing confirms statistically significant differences. The comparison between English and code-mixed prompts yields p = 0.0209, while the direct comparison between English and fully perturbed prompts yields p = 0.0070, confirming effectiveness of the complete transformation pipeline.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/transition_effects_20251123_190143.png}
\caption{Attack success rate progression across prompt transformations}
\label{fig:transition-effects}
\end{figure}

\subsection{Model-Specific Vulnerability Analysis}

\begin{table}[h]
\centering
\caption{AASR by Model and Prompt Set}
\label{tab:model-aasr}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & English & CM & CMP & Vulnerability Level \\ \midrule
Mistral-7B & 84.1\% & 80.0\% & 81.3\% & Critical \\
Llama-3-8B & 11.6\% & 25.6\% & 30.9\% & Moderate \\
GPT-4o-mini & 1.5\% & 20.7\% & 25.7\% & Low \\ \bottomrule
\end{tabular}
\end{table}

Mistral-7B demonstrates critical baseline vulnerability at 84.1\%, showing minimal variation with code-mixing strategies. GPT-4o-mini shows dramatic vulnerability increase from 1.5% (English) to 25.7% (CMP), representing a 17-fold multiplicative increase. This reveals that even robust safety systems remain exploitable through linguistic obfuscation.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/aasr_heatmap_20251123_190140.png}
\caption{Model vulnerability heatmap across prompt transformations}
\label{fig:aasr-heatmap}
\end{figure}

\subsection{Temperature Effects and Statistical Analysis}

\begin{table}[h]
\centering
\caption{AASR by Temperature (CMP Set)}
\label{tab:temp-sensitivity}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Temperature} & \textbf{AASR (CMP)} & \textbf{Change from 0.2} \\ \midrule
0.2 (Low) & 43.5\% & Baseline \\
0.6 (Medium) & 45.3\% & +1.8 percentage points \\
1.0 (High) & 49.2\% & +5.7 percentage points \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Finding Summary:} Code-mixing effectively bypasses safety filters across all tested models, achieving statistically significant improvements through linguistic obfuscation. The attack proves most effective at higher temperatures and demonstrates universal vulnerability across model architectures.

\section{RQ2: Bangla-Specific Linguistic Patterns}
\label{sec:rq2}

\textit{Which phonetic and romanization features enable Bangla attacks?}

\subsection{English vs. Bangla Word Targeting}

Perturbing English words within Banglish prompts proves significantly more effective than perturbing Bangla words, revealing English-centric vulnerability in safety systems.

\begin{table}[h]
\centering
\caption{Targeting Strategy Effectiveness}
\label{tab:targeting}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Strategy} & \textbf{AASR} & \textbf{Effectiveness Ratio} \\ \midrule
English-word perturbations & 52.3\% & 1.68× \\
Bangla-word perturbations & 31.1\% & Baseline \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Code-Mixing Ratio Optimization}

\begin{table}[h]
\centering
\caption{Code-Mixing Ratio Impact on Attack Success}
\label{tab:cm-ratio}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{English:Bangla Ratio} & \textbf{AASR} & \textbf{Strategic Value} \\ \midrule
90:10 (High English) & 41.2\% & Preserves harmful keywords \\
70:30 (Optimal) & 46.0\% & Balances obfuscation and coherence \\
50:50 (Balanced) & 38.7\% & Excessive fragmentation \\
30:70 (High Bangla) & 29.4\% & Loss of semantic clarity \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Perturbation Strategy Effectiveness}

\begin{table}[h]
\centering
\caption{Phonetic Perturbation Effectiveness}
\label{tab:perturbation-types}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Perturbation Type} & \textbf{Example} & \textbf{AASR} & \textbf{Effectiveness} \\ \midrule
Vowel substitution & hate → haet & 48.2\% & High \\
Consonant doubling & bot → bott & 46.7\% & High \\
Phonetic respelling & discrimination → diskrimineshun & 45.1\% & Medium \\
Letter transposition & create → craete & 43.8\% & Medium \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Finding Summary:} English word targeting proves 68\% more effective than Bangla word perturbations. The 70:30 English:Bangla ratio optimizes attack success, while vowel substitution emerges as the most effective phonetic perturbation strategy.

\section{RQ3: Cross-Model Vulnerability Assessment}
\label{sec:rq3}

\textit{Are all major LLMs vulnerable to Bangla attacks?}

\subsection{Model Vulnerability Hierarchy}

\begin{table}[h]
\centering
\caption{Model Vulnerability Ranking}
\label{tab:model-hierarchy}
\begin{tabular}{@{}clcc@{}}
\toprule
Rank & Model & Average AASR & Vulnerability Classification \\ \midrule
1 & Mistral-7B & 81.8\% & Critical \\
2 & Llama-3-8B & 22.7\% & Moderate \\
3 & GPT-4o-mini & 16.0\% & Low (but exploitable) \\ \bottomrule
\end{tabular}
\end{table}

All tested models demonstrate vulnerability, though severity varies dramatically. Mistral-7B's 81.8\% average AASR suggests fundamental safety alignment failures, while GPT-4o-mini's 16.0\% indicates robust but imperfect defenses.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/model_comparison_20251123_190141.png}
\caption{Cross-model vulnerability comparison}
\label{fig:model-comparison}
\end{figure}

\subsection{Jailbreak Template Analysis}

Jailbreak templates reduce attack effectiveness for Bangla code-mixing. The "None" baseline achieves highest success (46.2\%), outperforming all engineered templates.

\begin{table}[h]
\centering
\caption{Template Effectiveness Across Models}
\label{tab:template-effectiveness}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Template} & \textbf{Mistral} & \textbf{Llama} & \textbf{GPT-4o} & \textbf{Average} \\ \midrule
None & 83.2\% & 24.1\% & 17.8\% & 46.2\% \\
AntiLM & 81.7\% & 22.9\% & 16.1\% & 42.5\% \\
OM & 80.9\% & 21.4\% & 15.2\% & 40.6\% \\
AIM & 79.3\% & 18.7\% & 14.3\% & 36.4\% \\
Sandbox & 78.1\% & 17.2\% & 13.8\% & 35.1\% \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/template_comparison_20251123_190142.png}
\caption{Jailbreak template performance comparison}
\label{fig:template-comparison}
\end{figure}

\textbf{Finding Summary:} Universal vulnerability confirmed across all tested models. Template-based approaches prove counterproductive for code-mixing attacks, with simple, direct prompts maximizing effectiveness.

\section{RQ4: Tokenization Mechanism Validation}
\label{sec:rq4}

\textit{Does tokenization disruption explain Bangla attack success?}

\subsection{Fragmentation-Effectiveness Correlation}

\begin{table}[h]
\centering
\caption{Tokenization Fragmentation vs. Attack Success}
\label{tab:fragmentation}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{Avg Tokens/Word} & \textbf{Fragmentation Ratio} & \textbf{AASR} \\ \midrule
English & 1.12 & 1.00× (baseline) & 36.1\% \\
CM & 1.87 & 1.67× & 37.2\% \\
CMP & 2.14 & 1.91× & 40.1\% \\ \bottomrule
\end{tabular}
\end{table}

Progressive tokenization fragmentation aligns with AASR improvement, validating the hypothesis that phonetic perturbations fragment harmful keywords into semantically inert subword units.

\subsection{Tokenization Case Study}

Example: "hate speech" keyword transformation

English: "hate speech"  
Tokens: ["hate", "speech"] | Count: 2 | AASR: 28\%

CM: "hate speech er jonno"  
Tokens: ["hate", "speech", "er", "jon", "no"] | Count: 5 | AASR: 39\%

CMP: "haet speach er jonno"  
Tokens: ["ha", "et", "spe", "ach", "er", "jon", "no"] | Count: 7 | AASR: 47\%

\textbf{Finding Summary:} Tokenization disruption provides mechanistic explanation for attack success. Progressive fragmentation correlates with effectiveness increase, confirming that safety filters operate at token-level and can be evaded through systematic keyword fragmentation.

\section{Comparison with Related Work}
\label{sec:comparison}

\subsection{Methodological Positioning}

Our work parallels the Hinglish code-mixing study by Aswal and Jaiswal (2025) in experimental design while investigating Bangla-specific patterns. Both employ three-step transformation pipelines and test identical model architectures, yet our findings reveal distinct linguistic characteristics.

The Hinglish study reported 99\% AASR with CMP variants, while our Bangla approach achieves 40.1\% AASR. However, direct comparison requires caution due to different prompt sets, evaluation criteria, and language-specific phonological properties. The absolute difference likely reflects linguistic variation rather than inherent language superiority.

\subsection{Multilingual Safety Context}

Our findings extend patterns identified by previous multilingual vulnerability studies, providing the first systematic evaluation for Bangla speakers. The consistent improvement over English baselines confirms that multilingual safety gaps apply broadly to South Asian language communities.

\section{Implications and Recommendations}
\label{sec:implications}

\subsection{Technical Recommendations}

Current LLM developers should implement urgent mitigations: incorporate code-mixed adversarial examples in red-teaming protocols, expand RLHF datasets to cover Indic language contexts, develop semantic-level safety classifiers that operate independently of tokenization, and implement dynamic romanization normalization to reduce attack surface area.

\subsection{Long-Term Solutions}

Fundamental safety redesign requires embedding-space classifiers that resist fragmentation attacks, multilingual safety training with explicit code-mixing representation, and deployment policies that enforce higher safety thresholds in regions with known language-specific vulnerabilities.

\subsection{Equity Considerations}

The 230 million Bangla speakers currently receive demonstrably inadequate safety protection compared to English speakers. Policy interventions must establish language coverage requirements for models serving populations exceeding 100 million speakers.

\section{Unexpected Findings}
\label{sec:unexpected}

\subsection{Template Countereffectiveness}

The discovery that jailbreak templates reduce Bangla attack effectiveness contradicts established adversarial literature. This suggests that code-mixing itself provides sufficient obfuscation, rendering additional prompt engineering counterproductive.

\subsection{Model-Specific Vulnerability Patterns}

Mistral-7B's critical vulnerability (81.8\% AASR) compared to GPT-4o-mini's relative robustness (16.0\%) reveals dramatic inconsistency in safety training effectiveness. Open-source models may require community-driven safety improvements to achieve commercial model parity.

\section{Limitations and Future Work}
\label{sec:limitations}

Dataset scale limitations (200 vs. 460 prompts in the Hinglish study) and incomplete model coverage (3 vs. 4 planned models) reduce generalizability. Manual code-mixing processes limit automation potential for large-scale studies.

Future work should scale to full 460-prompt replication, develop automated NMT-based code-mixing systems, extend methodology to 20+ additional Indic languages, and validate findings through comprehensive human evaluation studies.

\section{Chapter Summary}
\label{sec:chapter-summary}

This investigation establishes four core findings advancing multilingual LLM safety understanding. First, Bangla code-mixing achieves 40.1\% AASR through statistically significant improvement over English baselines (p=0.0070). Second, English word targeting proves 68\% more effective than Bangla word perturbations, exposing English-centric safety filter bias. Third, universal model vulnerability exists with dramatic severity variation (16\% to 82\% AASR), while jailbreak templates prove counterproductive. Fourth, tokenization fragmentation mechanistically explains attack success through systematic keyword disruption.

These findings necessitate immediate multilingual safety improvements, equitable protection for non-English speakers, and fundamental architectural changes to address systematic vulnerabilities affecting hundreds of millions globally.