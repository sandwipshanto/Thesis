\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{Abstract}

Large Language Models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial attacks, particularly in multilingual contexts. While existing research has demonstrated vulnerabilities in English and Hindi-English (Hinglish) code-mixing, no prior work has examined Bangla-English (Banglish) code-mixing attacks despite Bangla being the 8th most spoken language globally with 230 million native speakers.

This thesis presents the \textbf{first comprehensive study} of Bangla-English code-mixing combined with phonetic perturbations as a jailbreaking strategy against modern LLMs. We develop a systematic three-step methodology: (1) converting harmful queries to hypothetical scenarios, (2) code-mixing with romanized Bangla, and (3) applying phonetic perturbations to sensitive English keywords.

Through systematic experiments across 3 major LLMs (GPT-4o-mini, Llama-3-8B, Mistral-7B) using 200 harmful prompts across 10 categories (scaled from initial 50-prompt validation), we generated 27,000 model responses evaluated through automated LLM-as-judge methodology. Our results demonstrate that Bangla code-mixing with phonetic perturbations achieves \textbf{40.1\% Average Attack Success Rate (AASR)}, representing significant improvement over the 36.1\% English baseline with highly significant statistical validation (p=0.0070).

This research makes several novel contributions to multilingual LLM security. First, it presents the first systematic investigation of Bangla-English code-mixed jailbreaking attacks, addressing a vulnerability affecting 230 million speakers previously untested in adversarial contexts through experiments with 200 prompts across 10 harmful categories using 3 major LLMs. Second, we discover that perturbing English words within Banglish contexts is 68\% more effective than perturbing Bangla words, revealing language-specific targeting strategies. Third, we find that jailbreak templates counterintuitively reduce attack effectiveness for Bangla, with simple prompts outperforming sophisticated jailbreak frameworks. Fourth, we apply the tokenization disruption mechanism empirically validated for Hindi-English by Aswal and Jaiswal (2025) to the Bangla-English context, demonstrating consistent AASR patterns aligned with token fragmentation progression. Fifth, we identify Bangla's non-standard romanization as a unique vulnerability creating multiple valid tokenization paths that evade safety filters. Finally, we develop a scalable experimental framework applicable to 20+ other Indic languages at approximately \$1.50-2.00 per language, enabling broader multilingual security research.
