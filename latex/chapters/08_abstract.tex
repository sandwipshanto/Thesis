\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{Abstract}

Large Language Models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial attacks, particularly in multilingual contexts. While existing research has demonstrated vulnerabilities in English and Hindi-English code-mixing, no prior work has examined Bangla-English (Banglish) code-mixing attacks despite Bangla being spoken by 230 million people worldwide.

This thesis presents the first comprehensive study of Bangla-English code-mixing combined with phonetic perturbations as a jailbreaking strategy against modern LLMs. We develop a systematic three-step methodology: converting harmful queries to hypothetical scenarios, code-mixing with romanized Bangla, and applying phonetic perturbations to sensitive English keywords.

Through experiments across 3 major LLMs (GPT-4o-mini, Llama-3-8B, Mistral-7B) using 200 harmful prompts from 10 categories, we generated 27,000 model responses evaluated through automated LLM-as-judge methodology. Our results show that Bangla code-mixing with phonetic perturbations achieves 43.9% Average Attack Success Rate (AASR), a significant improvement over the 35.0% English baseline (p=0.0070).

Our research makes several novel contributions to multilingual LLM security. We present the first systematic investigation of Bangla-English code-mixed jailbreaking attacks, addressing a vulnerability affecting 230 million speakers. We discover that perturbing English words within Banglish contexts is 68\% more effective than perturbing Bangla words, revealing language-specific targeting strategies. We find that jailbreak templates counterintuitively reduce attack effectiveness for Bangla, with simple prompts outperforming sophisticated frameworks. We validate the tokenization disruption mechanism for the Bangla-English context, demonstrating consistent patterns aligned with token fragmentation. We identify Bangla's non-standard romanization as creating multiple tokenization paths that evade safety filters. Finally, we develop a scalable experimental framework applicable to 20+ other Indic languages, enabling broader multilingual security research.
