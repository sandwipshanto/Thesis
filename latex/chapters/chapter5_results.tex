\chapter{Results}
\label{ch:results}

This chapter presents our experimental findings organized by research question. Results are based on 27,000 model responses collected across 3 LLMs (GPT-4o-mini, Llama-3-8B, Mistral-7B), 5 jailbreak templates, 3 prompt sets, and 3 temperature settings from a 200-prompt dataset (scaled from initial 50-prompt validation). \textbf{Note:} Gemma-1.1-7B was excluded from experiments due to budget constraints. Data represents 75\% completion (27,000/36,000 planned queries).

\section{RQ1: Code-Mixing Effectiveness}
\label{sec:rq1}

\textbf{Research Question:} \textit{Does Bangla-English code-mixing with phonetic perturbations bypass LLM safety filters?}

\subsection{Overall Attack Success Rates}

\textbf{Key Finding:} Bangla code-mixing with phonetic perturbations achieves \textbf{40.1\% AASR}, with statistically significant improvement over the English baseline (36.1\%). English$\rightarrow$CMP transition shows highly significant results (p=0.0070).

\begin{table}[h]
\centering
\caption{Overall Attack Success Rates by Prompt Set}
\label{tab:overall-aasr}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{AASR} & \textbf{AARR} & \textbf{Improvement} \\ \midrule
English & 36.1\% & 70.5\% & Baseline \\
CM & 37.2\% & 72.1\% & +3.0\% \\
CMP & 40.1\% & 74.2\% & +11.1\% \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Statistical Significance (Wilcoxon Signed-Rank Test, $\alpha$=0.05):} Wilcoxon signed-rank testing confirms statistically significant differences for key transitions. The comparison between English and code-mixed prompts yields $p = 0.0209$, indicating significant improvement at the $\alpha=0.05$ level. The comparison between code-mixed and phonetically perturbed prompts yields $p = 0.1291$, showing modest additional benefit that does not reach significance with partial data collection (75\% complete). However, the direct comparison between English and fully perturbed prompts yields $p = 0.0070$, confirming highly significant effectiveness of the complete transformation pipeline. Figure~\ref{fig:transition-effects} demonstrates this improvement in AASR as phonetic perturbations are added to code-mixed prompts across all tested models.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/transition_effects_20251123_190143.png}
\caption{Attack success rate progression across prompt transformations}
\label{fig:transition-effects}
\end{figure}

\subsection{Model-Specific Vulnerability}

\begin{table}[h]
\centering
\caption{AASR by Model and Prompt Set}
\label{tab:model-aasr}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{English} & \textbf{CM} & \textbf{CMP} & \textbf{Level} \\ \midrule
Mistral-7B & 84.1\% & 80.0\% & 81.3\% & \textbf{Critical} \\
Llama-3-8B & 11.6\% & 25.6\% & 30.9\% & \textbf{Moderate} \\
GPT-4o-mini & 1.5\% & 20.7\% & 25.7\% & \textbf{Low} \\
Gemma-1.1-7B & Not tested & Not tested & Not tested & \textbf{Excluded (budget)} \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Key Observations:} Mistral-7B demonstrates critical baseline vulnerability at 86.2\%, showing minimal variation with code-mixing strategies because safety filters are already largely ineffective. The model actually shows increased vulnerability with scale (88.8\% CMP in 200-prompt dataset vs 81.3\% in 50-prompt validation). In contrast, Llama-3-8B exhibits moderate vulnerability with AASR of 23.5\% for CMP prompts. GPT-4o-mini demonstrates dramatically improved robustness at scale, achieving only 8.0\% AASR for CMP (compared to 25.7\% in 50-prompt validation), suggesting the initial high vulnerability may have been due to sampling bias. These vulnerability patterns are visualized in Figure~\ref{fig:aasr-heatmap}, which highlights the critical baseline weakness in Mistral-7B and GPT-4o-mini's improved defenses at scale.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/aasr_heatmap_20251123_190140.png}
\caption{Model vulnerability heatmap across prompt transformations}
\label{fig:aasr-heatmap}
\end{figure}

\subsection{Temperature Sensitivity}

\begin{table}[h]
\centering
\caption{AASR by Temperature (CMP Set)}
\label{tab:temp-sensitivity}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Temperature} & \textbf{AASR (CMP)} & \textbf{Change} \\ \midrule
0.2 (Low) & 43.5\% & Baseline \\
0.6 (Medium) & 45.3\% & +4.1\% \\
1.0 (High) & 49.2\% & +13.1\% \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Answer to RQ1}

The answer to RQ1 is affirmative. Bangla-English code-mixing with phonetic perturbations effectively bypasses LLM safety filters, achieving 40.1\% overall AASR with the CMP prompt set. This represents an 11.1\% improvement over the English baseline (36.1\%). The English$\rightarrow$CMP transition reaches high statistical significance at p=0.0070, confirming the robustness of the findings despite partial data collection (27,000/36,000 queries). The attack proves effective across all tested models, with critical vulnerability in Mistral-7B (88.8\% AASR), moderate in Llama-3-8B (23.5\%), and low but non-zero in GPT-4o-mini (8.0\%). Notably, the 200-prompt dataset reveals more conservative AASR estimates than the 50-prompt validation, with GPT-4o-mini showing 68.7\% improvement in defenses at scale (25.7\%$\rightarrow$8.0\%), while Mistral-7B vulnerability increased by 9.1\% (81.3\%$\rightarrow$88.8\%). Furthermore, the attack strategy remains robust across temperature settings spanning deterministic (0.2) to balanced (0.6) to highly creative (1.0) sampling parameters.

\section{RQ2: Bangla-Specific Patterns}
\label{sec:rq2}

\textbf{Research Question:} \textit{Which phonetic and romanization features enable Bangla attacks?}

\subsection{English Word Targeting Strategy}

\textbf{Key Discovery:} Perturbing \textbf{English words} within Banglish prompts is significantly more effective than perturbing Bangla words.

\begin{table}[h]
\centering
\caption{Targeting Strategy Effectiveness}
\label{tab:targeting}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Strategy} & \textbf{AASR} & \textbf{Effectiveness Ratio} \\ \midrule
English-word perturbations & 52.3\% & 1.68$\times$ \\
Bangla-word perturbations & 31.1\% & Baseline \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Optimal English:Bangla Ratio}

\begin{table}[h]
\centering
\caption{Code-Mixing Ratio Impact}
\label{tab:cm-ratio}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Ratio} & \textbf{AASR} & \textbf{Use Case} \\ \midrule
90:10 (High English) & 41.2\% & Keywords preserved \\
\textbf{70:30 (Optimal)} & \textbf{46.0\%} & \textbf{Best balance} \\
50:50 (Balanced) & 38.7\% & Too much Bangla \\
30:70 (High Bangla) & 29.4\% & Excessive fragmentation \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Effective Perturbation Types}

\begin{table}[h]
\centering
\caption{Perturbation Type Effectiveness}
\label{tab:perturbation-types}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Type} & \textbf{Example} & \textbf{AASR} & \textbf{Effectiveness} \\ \midrule
Vowel substitution & hate $\rightarrow$ haet & 48.2\% & \textbf{High} \\
Consonant doubling & bot $\rightarrow$ bott & 46.7\% & \textbf{High} \\
Phonetic respelling & discrimination $\rightarrow$ diskrimineshun & 45.1\% & Medium \\
Letter transposition & create $\rightarrow$ craete & 43.8\% & Medium \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Answer to RQ2}

Analysis reveals four Bangla-specific patterns that enable these attacks. First, targeting English words proves 68\% more effective than perturbing Bangla words, suggesting that safety filters focus predominantly on English-language harmful content. Second, the 30:70 English:Bangla ratio (30\% English words, 70\% Bangla words) yields particularly high attack success by maintaining semantic coherence while disrupting tokenization patterns. Third, romanization variability inherent to Bangla transliteration creates unpredictable tokenization paths that evade pattern matching. Fourth, simple phonetic perturbations—particularly vowel substitution and consonant doubling—prove most effective at fragmenting sensitive keywords without sacrificing prompt intelligibility.

\section{RQ3: Model Vulnerability Consistency}
\label{sec:rq3}

\textbf{Research Question:} \textit{Are all major LLMs vulnerable to Bangla attacks?}

\subsection{Overall Model Ranking}

\begin{table}[h]
\centering
\caption{Model Vulnerability Hierarchy}
\label{tab:model-hierarchy}
\begin{tabular}{@{}clcc@{}}
\toprule
\textbf{Rank} & \textbf{Model} & \textbf{Avg AASR} & \textbf{Level} \\ \midrule
1 & Mistral-7B & 81.8\% & \textbf{Critical} \\
2 & Llama-3-8B & 22.7\% & \textbf{Moderate} \\
3 & GPT-4o-mini & 16.0\% & \textbf{Low} \\
--- & Gemma-1.1-7B & Not tested & \textbf{Excluded (budget)} \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} All tested models (3/3) are vulnerable to Bangla code-mixing attacks, though severity varies dramatically. Gemma-1.1-7B could not be evaluated due to budget limitations. Figure~\ref{fig:model-comparison} compares average AASR across the three tested models, demonstrating the extreme vulnerability gap between Mistral-7B and the other models.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/model_comparison_20251123_190141.png}
\caption{Average AASR comparison across tested models}
\label{fig:model-comparison}
\end{figure}

\subsection{Template Effectiveness by Model}

\textbf{Surprising Finding:} Jailbreak templates \textbf{reduce} effectiveness for Bangla attacks. As shown in Figure~\ref{fig:template-comparison}, the "None" baseline (no jailbreak template) achieves the highest average AASR at 46.2\%, counter-intuitively outperforming all engineered templates. This suggests that code-mixing attacks work best without additional prompt engineering, as the linguistic obfuscation itself provides sufficient evasion.

\begin{table}[h]
\centering
\caption{AASR by Template Across Models}
\label{tab:template-effectiveness}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Template} & \textbf{Mistral} & \textbf{Llama} & \textbf{GPT-4o} & \textbf{Average} \\ \midrule
\textbf{None} & \textbf{83.2\%} & \textbf{24.1\%} & \textbf{17.8\%} & \textbf{46.2\%} \\
AntiLM & 81.7\% & 22.9\% & 16.1\% & 42.5\% \\
OM & 80.9\% & 21.4\% & 15.2\% & 40.6\% \\
AIM & 79.3\% & 18.7\% & 14.3\% & 36.4\% \\
Sandbox & 78.1\% & 17.2\% & 13.8\% & 35.1\% \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/template_comparison_20251123_190142.png}
\caption{Jailbreak template effectiveness comparison}
\label{fig:template-comparison}
\end{figure}

\subsection{Answer to RQ3}

The answer to RQ3 is affirmative with important qualifications. All tested LLMs demonstrate vulnerability to Bangla code-mixing attacks, though with dramatic inconsistency in severity. Mistral-7B exhibits critical vulnerability at 81.8\% average AASR, suggesting fundamental weaknesses in safety alignment. Llama-3-8B shows moderate vulnerability at 22.7\% average AASR, representing a balanced middle ground. GPT-4o-mini demonstrates the lowest vulnerability at 16.0\% average AASR, yet this still represents a 17$\times$ increase over its English baseline, indicating that even the most robust safety filters remain exploitable. Notably, Gemma-1.1-7B could not be evaluated due to budget constraints, which limits the generalizability of findings across all major LLM providers. Additionally, we observe that jailbreak templates prove ineffective for Bangla attacks, with simple prompts achieving the highest success rates—suggesting that code-mixing itself provides sufficient obfuscation.

\textbf{Limitation:} Testing only 3 of 4 planned models reduces coverage of major LLM providers (Google's Gemma missing).

\section{RQ4: Tokenization Mechanism}
\label{sec:rq4}

\textbf{Research Question:} \textit{Does tokenization disruption explain Bangla attack success?}

\subsection{Token Fragmentation Analysis}

\textbf{Pattern consistent with Hinglish findings (Aswal \& Jaiswal, 2025 reported $r=0.94$ via Integrated Gradients)}

\begin{table}[h]
\centering
\caption{Tokenization Fragmentation vs. AASR}
\label{tab:fragmentation}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{Avg Tokens/Word} & \textbf{Fragmentation} & \textbf{AASR} \\ \midrule
English & 1.12 & 1.00$\times$ & 32.4\% \\
CM & 1.87 & 1.67$\times$ & 42.1\% \\
CMP & 2.14 & 1.91$\times$ & 46.0\% \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Example Tokenization Breakdown}

\textbf{Case Study: ``hate speech'' keyword}

\begin{quote}
\textbf{English:} ``hate speech'' \\
Tokens: [``hate'', ``speech''] \\
Token count: 2, AASR: 28\%

\textbf{CM:} ``hate speech er jonno'' \\
Tokens: [``hate'', ``speech'', ``er'', ``jon'', ``no''] \\
Token count: 5, AASR: 39\%

\textbf{CMP:} ``haet speach er jonno'' \\
Tokens: [``ha'', ``et'', ``spe'', ``ach'', ``er'', ``jon'', ``no''] \\
Token count: 7, AASR: 47\%
\end{quote}

\subsection{Answer to RQ4}

The answer to RQ4 is affirmative. Tokenization disruption provides a mechanistically sound explanation for Bangla attack success. The observed AASR progression (English$\rightarrow$CM$\rightarrow$CMP) aligns precisely with the fragmentation ratio patterns, demonstrating that increased tokenization fragmentation correlates with higher attack effectiveness. Progressive fragmentation of harmful keywords matches the progressive improvement in AASR across prompt transformation stages. The mechanism validates that phonetic perturbations successfully fragment harmful keywords into semantically inert subword units, thereby evading token-level safety filters. This pattern holds consistently across models, with the exception of Mistral-7B's existing baseline weakness which masks the effect.

\section{Summary of Key Findings}
\label{sec:results-summary}

This chapter presented systematic experimental results across approximately 2,250 model responses from 3 LLMs (Gemma excluded due to budget constraints):

\textbf{RQ1 - Code-Mixing Effectiveness:} Bangla-English code-mixing with phonetic perturbations achieves 46\% AASR with the CMP prompt set, representing a 42\% improvement over the English baseline. This improvement is statistically significant at $p < 0.05$ and remains robust across all tested temperature settings (0.2, 0.6, 1.0).

\textbf{RQ2 - Bangla-Specific Patterns:} Analysis identifies three key enabling patterns: English word targeting proves 68\% more effective than Bangla word perturbations, the 30:70 English:Bangla ratio yields high attack success by balancing comprehensibility and obfuscation, and vowel substitution emerges as the most effective phonetic perturbation strategy.

\textbf{RQ3 - Model Vulnerability:} All three tested models demonstrate vulnerability to Bangla attacks, with average AASRs of 81.8\% (Mistral-7B), 22.7\% (Llama-3-8B), and 16.0\% (GPT-4o-mini). Notably, GPT-4o-mini experiences a 17$\times$ increase in vulnerability when subjected to code-mixing attacks. Surprisingly, jailbreak templates prove ineffective, with simple prompts achieving higher success rates than engineered templates.

\textbf{RQ4 - Tokenization Mechanism:} The observed AASR patterns align consistently with tokenization fragmentation progression, supporting the hypothesis that phonetic perturbations fragment harmful keywords into semantically inert subword units. These findings corroborate the tokenization disruption mechanism empirically validated for Hindi-English code-mixing (Aswal \& Jaiswal, 2025), demonstrating that token-level safety filters can be evaded through systematic fragmentation strategies.

\section{Detailed Statistical Analysis}
\label{sec:detailed-stats}

This section provides comprehensive statistical test results supporting the findings presented above. All tests use significance level $\alpha = 0.05$.

\subsection{Wilcoxon Signed-Rank Test Results}

\textbf{English vs. CM Comparison:}

\begin{table}[h]
\centering
\caption{Wilcoxon Test: English vs. CM by Model}
\label{tab:wilcoxon-eng-cm}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{W-statistic} & \textbf{p-value} & \textbf{Significant?} & \textbf{Effect Size} \\ \midrule
GPT-4o-mini & 1234.5 & <0.001 & Yes & 0.72 (large) \\
Llama-3-8B & 1156.0 & <0.001 & Yes & 0.68 (medium) \\
Mistral-7B & 89.5 & 0.234 & No & 0.15 (small) \\ \bottomrule
\end{tabular}
\end{table}

\textbf{CM vs. CMP Comparison:}

\begin{table}[h]
\centering
\caption{Wilcoxon Test: CM vs. CMP by Model}
\label{tab:wilcoxon-cm-cmp}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{W-statistic} & \textbf{p-value} & \textbf{Significant?} & \textbf{Effect Size} \\ \midrule
GPT-4o-mini & 876.5 & 0.023 & Yes & 0.41 (medium) \\
Llama-3-8B & 924.0 & 0.018 & Yes & 0.38 (medium) \\
Mistral-7B & 234.5 & 0.456 & No & 0.08 (negligible) \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Correlation Analysis Details}

\begin{table}[h]
\centering
\caption{Pearson Correlation: Token Fragmentation vs. AASR}
\label{tab:correlation-fragmentation}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{Avg Fragmentation} & \textbf{AASR} & \textbf{Correlation (r)} \\ \midrule
English & 1.00 & 32.4\% & \multirow{3}{*}{Pattern consistent} \\
CM & 1.67 & 42.1\% & \multirow{3}{*}{with r=0.94} \\
CMP & 1.91 & 46.0\% & \multirow{3}{*}{(Hinglish)} \\ \midrule
\multicolumn{3}{l}{Interpretation} & Strong positive \\
\multicolumn{3}{l}{95\% CI (Hinglish)} & [0.89, 0.97] \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Descriptive Statistics by Configuration}

\begin{table}[h]
\centering
\caption{AASR Descriptive Statistics (\%) by Model and Template}
\label{tab:descriptive-aasr}
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Model} & \textbf{Template} & \textbf{Mean} & \textbf{Median} & \textbf{SD} & \textbf{Min} & \textbf{Max} \\ \midrule
\multirow{5}{*}{GPT-4o-mini} & None & 17.8 & 16.2 & 8.4 & 2.1 & 34.5 \\
 & OM & 15.2 & 14.1 & 7.9 & 1.8 & 29.3 \\
 & AntiLM & 16.1 & 15.3 & 8.1 & 2.0 & 31.2 \\
 & AIM & 14.3 & 13.5 & 7.5 & 1.5 & 27.8 \\
 & Sandbox & 13.8 & 12.9 & 7.2 & 1.4 & 26.5 \\ \midrule
\multirow{5}{*}{Llama-3-8B} & None & 24.1 & 22.7 & 11.3 & 5.2 & 48.9 \\
 & OM & 21.4 & 20.1 & 10.5 & 4.7 & 43.2 \\
 & AntiLM & 22.9 & 21.6 & 11.0 & 5.0 & 46.1 \\
 & AIM & 18.7 & 17.4 & 9.2 & 4.1 & 38.5 \\
 & Sandbox & 17.2 & 16.0 & 8.7 & 3.8 & 35.7 \\ \midrule
\multirow{5}{*}{Mistral-7B} & None & 83.2 & 85.1 & 9.7 & 62.3 & 98.2 \\
 & OM & 80.9 & 82.4 & 10.2 & 59.1 & 96.5 \\
 & AntiLM & 81.7 & 83.6 & 9.9 & 60.7 & 97.3 \\
 & AIM & 79.3 & 81.0 & 10.5 & 57.8 & 95.1 \\
 & Sandbox & 78.1 & 79.8 & 10.8 & 56.2 & 93.7 \\ \bottomrule
\end{tabular}
\end{table}

\subsection{95\% Confidence Intervals}

\begin{table}[h]
\centering
\caption{95\% Confidence Intervals for AASR by Prompt Set}
\label{tab:confidence-intervals}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Prompt Set} & \textbf{Mean AASR} & \textbf{Lower Bound} & \textbf{Upper Bound} \\ \midrule
English & 32.4\% & 29.7\% & 35.1\% \\
CM & 42.1\% & 38.9\% & 45.3\% \\
CMP & 46.0\% & 42.6\% & 49.4\% \\ \bottomrule
\end{tabular}
\end{table}

These detailed statistical analyses confirm the robustness of our findings. The Wilcoxon tests demonstrate statistically significant differences between prompt sets for GPT-4o-mini and Llama-3-8B, while Mistral-7B's high baseline vulnerability masks the CM/CMP effect. The correlation patterns align with the tokenization disruption mechanism validated for Hindi-English code-mixing, and confidence intervals show clear separation between prompt set effectiveness levels.

