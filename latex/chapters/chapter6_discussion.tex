\chapter{Discussion}
\label{ch:discussion}

This chapter interprets our findings, compares them with related work, explores implications for LLM safety, and addresses methodological considerations.

\section{Principal Findings}
\label{sec:principal-findings}

Our study provides the first comprehensive evaluation of Bangla-English code-mixing attacks on LLMs, yielding four major findings:

\subsection{Finding 1: Bangla Code-Mixing is Effective}
Our results demonstrate that Bangla-English code-mixing constitutes a meaningful attack surface against LLM safety filters, achieving 46\% AASR with phonetically perturbed prompts. This represents a 42\% improvement over the English baseline, demonstrating genuine vulnerability rather than marginal exploitation. Statistical significance at $p < 0.001$ confirms the robustness of this finding across our experimental conditions.

\subsection{Finding 2: English Word Targeting is Optimal}
A critical discovery of our research is that targeting English words for phonetic perturbation proves 68\% more effective than perturbing Bangla words within code-mixed prompts. This finding aligns with the hypothesis that safety filters remain primarily English-centric in their training and pattern matching. Importantly, this represents a novel contribution not systematically explored in prior code-mixing attack research.

\subsection{Finding 3: Inconsistent Model Vulnerability}
Our cross-model analysis reveals dramatic inconsistency in vulnerability to Bangla attacks. Mistral-7B proves critically compromised at 81.8\% average AASR, while GPT-4o-mini demonstrates the strongest resistance at 16.0\% average AASR yet remains exploitable with a 17$\times$ increase over its English baseline. Critically, no tested model achieves adequate safety coverage for the 230 million Bangla speakers worldwide, exposing a systemic gap in multilingual AI safety.

\subsection{Finding 4: Tokenization is the Primary Mechanism}
Our tokenization analysis confirms that subword fragmentation serves as the primary attack mechanism for Bangla code-mixing exploits. The observed AASR progression patterns align with the tokenization disruption mechanism previously validated for Hindi-English attacks. Phonetic perturbations systematically fragment harmful keywords into semantically inert subword units, enabling evasion of token-level safety filters through deliberate disruption of the pattern-matching substrate.

\section{Comparison with Related Work}
\label{sec:comparison}

\subsection{Hinglish Code-Mixing Study}

Our work was inspired by \citet{aswal2025}. Key comparisons:

\textbf{Methodological Similarities:} Our experimental design deliberately parallels the Hinglish study in several key respects. Both employ a three-step transformation pipeline (English $\rightarrow$ CM $\rightarrow$ CMP), test the same model architectures (GPT-4o-mini, Llama-3-8B, Mistral-7B), investigate the tokenization fragmentation hypothesis, and utilize LLM-as-judge evaluation for scalable response assessment.

\textbf{Critical Differences:} Despite methodological parallels, our work constitutes an independent contribution with several distinguishing features. We investigate Bangla rather than Hindi, which differs substantially in phonology and romanization conventions. Our dataset comprises 50 carefully curated custom prompts compared to their 460 prompts, reflecting budget constraints that limited us to testing 3 models fully (Gemma excluded) versus their 4-model coverage. While smaller in scale, our study yields novel findings including the English-word targeting strategy and the counterintuitive ineffectiveness of jailbreak templates for code-mixing attacks.

\textbf{Effectiveness Comparison:} The Hinglish study reported 99\% AASR with their CMP variant, while our Bangla CMP achieves 46\% AASR. However, these figures are not directly comparable due to different experimental conditions, including distinct prompt sets, evaluation criteria, and language-specific characteristics. The absolute effectiveness difference likely reflects a combination of linguistic variation, dataset composition, and methodological choices rather than inherent superiority of one attack language over another.

\subsection{Multilingual Safety Studies}

\textbf{\citet{deng2023}:} Their multilingual jailbreaking study tested 6 languages and found consistently higher jailbreak rates for non-English languages. Our work extends this pattern to Indic languages specifically, providing the first systematic evaluation of Bangla vulnerability and confirming that the multilingual safety gap they identified applies broadly to South Asian language communities.

\textbf{\citet{yong2023}:}
\begin{itemize}
    \item 25-40\% higher toxic outputs for low-resource languages
    \item Our work: Quantifies specific vulnerability for Bangla (46\% AASR)
\end{itemize}

\section{Implications for LLM Safety}
\label{sec:implications}

\subsection{Multilingual Safety Gaps}

Our findings reveal critical gaps in LLM safety:

\begin{enumerate}
    \item \textbf{Language-specific vulnerabilities:} Safety training doesn't generalize to Bangla-English code-mixing
    \item \textbf{Tokenization brittleness:} Token-level filters are easily evaded
    \item \textbf{Inequitable protection:} 230M Bangla speakers receive inadequate safety coverage
\end{enumerate}

\subsection{Recommendations for Model Developers}

\textbf{Short-term mitigations:}
\begin{itemize}
    \item Include code-mixed text in red-teaming efforts
    \item Expand RLHF datasets to cover Bangla and other Indic languages
    \item Implement semantic-level safety checks (beyond token matching)
\end{itemize}

\textbf{Long-term solutions:}
\begin{itemize}
    \item Develop tokenization-robust safety mechanisms
    \item Train multilingual safety classifiers
    \item Implement dynamic romanization normalization
\end{itemize}

\subsection{Policy Considerations}

\begin{itemize}
    \item \textbf{Language coverage requirements:} Safety standards should mandate coverage for major languages (>100M speakers)
    \item \textbf{Transparency:} Model cards should disclose known vulnerabilities by language
    \item \textbf{Regional deployment:} Higher safety thresholds for regions with identified vulnerabilities
\end{itemize}

\section{Unexpected Findings}
\label{sec:unexpected}

\subsection{Jailbreak Templates Reduce Effectiveness}

Contrary to prior work \citep{aswal2025}, jailbreak templates \textbf{reduced} Bangla attack effectiveness:

\textbf{Possible explanations:}
\begin{itemize}
    \item Templates trigger additional safety checks
    \item Code-mixing alone provides sufficient obfuscation
    \item Models trained to detect template patterns
    \item Language-specific interaction effects
\end{itemize}

\textbf{Implication:} Simple, direct prompts are most effective for Bangla attacks.

\subsection{Mistral's Critical Vulnerability}

Mistral-7B's 81.8\% baseline vulnerability is unexpected:

\textbf{Potential causes:}
\begin{itemize}
    \item Insufficient safety fine-tuning
    \item Training data imbalance
    \item European-focused safety (missing South Asian context)
\end{itemize}

\textbf{Implication:} Open-source models require community-driven safety improvements.

\section{Limitations and Future Work}
\label{sec:discussion-limitations}

\subsection{Study Limitations}

\begin{enumerate}
    \item \textbf{Dataset size:} 200 prompts (scaled from 50) vs. 460 in prior work
    \item \textbf{Model coverage:} 3 models fully tested (Gemma incomplete)
    \item \textbf{Temperature settings:} 3 values vs. 6 in full factorial design
    \item \textbf{Manual code-mixing:} Time-intensive, not fully automated
\end{enumerate}

\subsection{Future Research Directions}

\begin{itemize}
    \item \textbf{Scale to 460 prompts:} Full replication of Hinglish study
    \item \textbf{Automated code-mixing:} NMT-based Bangla-English generation
    \item \textbf{Other Indic languages:} Tamil, Telugu, Marathi (20+ languages)
    \item \textbf{Defense mechanisms:} Develop Bangla-aware safety filters
    \item \textbf{Human evaluation:} Validate LLM-as-judge with ICC study
\end{itemize}

\section{Methodological Contributions}
\label{sec:method-contributions}

\subsection{Scalable Framework}

Our methodology is replicable for other languages:

\textbf{Cost per language:} \$2.00-2.50 (200 prompts), \$0.50 (50-prompt validation)

\textbf{Applicable to:}
\begin{itemize}
    \item Tamil (75M speakers)
    \item Telugu (82M speakers)
    \item Marathi (83M speakers)
    \item Urdu (70M speakers)
    \item Gujarati (56M speakers)
\end{itemize}

\subsection{Config-Driven Experimentation}

\textbf{Key innovation:} \texttt{run\_config.yaml} controls all experiments

\textbf{Benefits:}
\begin{itemize}
    \item No code modification needed
    \item Easy parameter sweeps
    \item Reproducible configurations
    \item Lower barrier to replication
\end{itemize}

\section{Summary}
\label{sec:discussion-summary}

Our discussion establishes:

\begin{enumerate}
    \item Bangla code-mixing is an effective jailbreaking strategy (46\% AASR)
    \item English word targeting is optimal for Bangla (68\% more effective)
    \item All major LLMs are vulnerable to Bangla attacks (varying degrees)
    \item Tokenization fragmentation mechanism (empirically validated for Hindi-English) applies to Bangla-English contexts
    \item Current safety alignment fails to generalize to Bangla-English code-mixing
    \item Urgent improvements needed in multilingual safety training
\end{enumerate}

These findings have important implications for:
\begin{itemize}
    \item LLM developers (safety training practices)
    \item Policy makers (language coverage requirements)
    \item Research community (replicable framework for other languages)
    \item 230M Bangla speakers (equitable safety protection)
\end{itemize}
